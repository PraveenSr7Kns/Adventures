-- Installation Instructions of Postgres16.5 and PostGIS on Amazon Linux 2023
-- ------------------------------------------------------------------------

-- It is not a script; rather, it comprises instructions for setup. Read and follow each steps carefully :)

-- My System config (Where I am installing)
-- ----------------------------------------
-- NAME="Amazon Linux"
-- ARCHITECTURE="x86"
-- VERSION="2023"
-- ID="amzn"
-- ID_LIKE="fedora"
-- VERSION_ID="2023"
-- PLATFORM_ID="platform:al2023"
-- PRETTY_NAME="Amazon Linux 2023.6.20250211"

-- PostgresSQL
-- -----------
-- Let's start with Postgres Installation
-- First, Update the machine - The installation is same for x64 as well
sudo dnf update

-- Use the below command for installing postgers
-- In My case, I am using version 16
-- Current version is 16 but I am going with 16 as it is not available in dnf
sudo dnf install -y postgresql16.x86_64 postgresql16-server

-- Note** - install postgres devel and contrib packages, dnf search to get the package
-- contrib and devel packages are mandatory in this installations
-- In my case,
sudo dnf install postgresql16-contrib.aarch64
sudo dnf install postgresql16-server-devel.aarch64

-- Initialize after installing successfully
sudo postgresql-setup --initdb

-- Start the service
sudo systemctl start postgresql

-- Enable the Postgres
sudo systemctl enable postgresql
-- You might see below
Created symlink /etc/systemd/system/multi-user.target.wants/postgresql.service â†’ /usr/lib/systemd/system/postgresql.service.

-- check the status, after all the above you should be seeing the positive response
sudo systemctl status postgresql

-- Before you do any config changes, You need to update the password of "postgres" user
-- if not, you may face login issue with the default user "postgres"

-- in my case, I am following below
sudo su - postgres
psql -U postgres

-- Add a password for your PostgreSQL admin

ALTER USER postgres WITH PASSWORD 'xxxxxxx';

-- Create user credentials for different users.
-- Replace username with the username you want. Replace $password with the password you want.
CREATE USER username SUPERUSER;
ALTER USER username WITH PASSWORD '$password';

CREATE USER username NOSUPERUSER;
ALTER USER username WITH PASSWORD '$password';

-- Restart after
sudo systemctl restart postgresql

-- Continue below

-- Below or look for config file location
-- If you are not seeing on the below dir, use find / -name pg_hba.conf 
sudo cp /var/lib/pgsql/data/pg_hba.conf /var/lib/pgsql/data/pg_hba.conf.bak
sudo vim /var/lib/pgsql/data/pg_hba.conf

--Scroll down until you see something like this, by default:

# TYPE  DATABASE        USER            ADDRESS                 METHOD

# "local" is for Unix domain socket connections only
local   all             all                                     ident
# IPv4 local connections:
host    all             all             127.0.0.1/32            ident
# IPv6 local connections:
host    all             all             ::1/128                 ident

-- Change it to read like this:
# TYPE  DATABASE        USER            ADDRESS                 METHOD

# "local" is for Unix domain socket connections only
local   all             all                                     md5
# IPv4 local connections:
host    all             username	        127.0.0.1/32        trust
# IPv6 local connections:
host    all             all             ::1/128                 md5

-- Double check the above step, or It may issue in log-in

-- take a backup of the below file, you might need it later
sudo cp /var/lib/pgsql/data/postgresql.conf /var/lib/pgsql/data/postgresql.conf.bak
sudo vim /var/lib/pgsql/data/postgresql.conf

-- Uncomment the line:
#listen_addresses = 'localhost'          # what IP address(es) to listen on;

-- Update the line to enable connections from any IP addresses:
listen_addresses='*'

-- Uncomment the line:
#port = 5432

-- To read like this:
port = 5432

-- Change shared_buffers Accorging to the need
shared_buffers = 128MB                  # min 128kB

-- In My case,
shared_buffers = 2GB                    # min 128kB

-- Change work_mem Accorging to your need
-- Uncomment below line
#work_mem = 4MB				# min 64kB

-- In My case
work_mem = 50MB				# min 64kB

-- Uncomment the line
#effective_cache_size = 4GB

-- To read like this
effective_cache_size = 4GB

-- Uncomment the line
#log_destination = 'stderr'              # Valid values are combinations of

-- To read like this
log_destination = 'stderr'              # Valid values are combinations of

-- Uncomment the line
#log_directory = 'log'                  # directory where log files are written,

-- To read like this
log_directory = 'log'                  # directory where log files are written,

-- Uncomment the line
#log_rotation_size = 10MB                # Automatic rotation of logfiles will

-- To read like this
log_rotation_size = 10MB                # Automatic rotation of logfiles will

-- Uncomment the line
#log_line_prefix = '%m [%p] '            # special values:

-- To read like this
log_line_prefix = '%m [%p] '            # special values:

-- Update below (Based on the needs, I am Setting up for US)
lc_messages = 'C.UTF-8'                 # locale for system error message
                                        # strings
lc_monetary = 'C.UTF-8'                 # locale for monetary formatting
lc_numeric = 'C.UTF-8'                  # locale for number formatting
lc_time = 'C.UTF-8'                             # locale for time formatting

-- To like this
lc_messages = 'en_US.UTF-8'                     # locale for system error message strings
lc_monetary = 'en_US.UTF-8'                     # locale for monetary formatting
lc_numeric = 'en_US.UTF-8'                      # locale for number formatting
lc_time = 'en_US.UTF-8'                         # locale for time formatting

-- Uncomment the line
#max_locks_per_transaction = 64          # min 10

-- Change like this
max_locks_per_transaction = 128          # min 10

-- Uncomment the line (Optional, I am using some scheduled jobs so I have enabled it)
-- Mind it, You need to create pg_cron extension on DB before you enable it. Unless Postgres will not start/restart
#shared_preload_libraries = ''

-- Change like this
shared_preload_libraries = 'pg_cron'

-- Restart once
-- Log into the postgresql

-- Login with posgres user
psql -U postgres
-- Enter the passowrd you have configured
-- In my case, I am following below
CREATE DATABASE geotiger OWNER praveenkns;
GRANT ALL PRIVILEGES ON DATABASE geotiger TO praveenkns;
ALTER ROLE praveenkns CREATEDB;

-- We are done with the PostgresSQL Installation, Lets Move on to PostGIS
-- Here's the tricky part begins, Please read all the below once then proceed with the installation
-- You will be seeing some of the issues I have faced and what I have done to resolve.

-- PostGIS:
-- --------
-- Some prerequisites
-- prerequisites? Yes. Missing below can stop any installation, then you will have to install everything in a loop
-- You need these to proceed with further installation, Coz I have collected all them from many failures!
-- Package may vary, use dnf search
sudo yum install gcc make gcc-c++ libtool libxml2-devel
sudo dnf install libcurl-devel
sudo dnf install libtiff-devel
sudo dnf install boost boost-devel
sudo dnf install gmp gmp-devel mpfr mpfr-devel
sudo yum install libxml2-devel
sudo yum install json-c-devel
sudo yum install protobuf-c-devel
sudo dnf install libcurl.aarch64 (To check -> curl --version)
sudo dnf install libtiff.aarch64 (To check -> rpm -qi libtiff)
sudo dnf install libpng.aarch64 (To check -> rpm -qi libpng)

-- Make sure to create a directory for every installation to avoid confusion
-- Remember where you are downloading the files for the process
-- In my case, /home/user_name

-- Check cmake version
cmake --version

-- Install cmake from dnf search if not installed
sudo dnf search cmake

-- Install GEOS - Use latest vesion/required
-- In my case, 3.13.0
mkdir Geos
cd Geos
wget https://download.osgeo.org/geos/geos-3.13.0.tar.bz2
tar xjvf geos-3.13.0.tar.bz2
cd geos-3.13.0
./configure
make
sudo make install
-- To check installed version
geos-config --version

-- Install sqlite3 - Use latest Version/required
mkdir Sqlite
cd Sqlite
wget https://www.sqlite.org/2025/sqlite-autoconf-3490000.tar.gz
tar xvfz sqlite-autoconf-3490000.tar.gz
cd sqlite-autoconf-3490000
./configure --prefix=/usr/local --enable--rtree (Note** RTree is an important one, Search it)
make
sudo make install
-- To check installed version
sqlite3 --version


-- set the PKG_CONFIG_PATH to find the sqlite3.pc file

export PKG_CONFIG_PATH=/your/path/name

-- use find command to know the path
-- In my case
export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig

-- Remember these CMake configs, use when it is needed, for release warnings etc
-- cmake -DCMAKE_BUILD_TYPE=Release ..
-- Note** find the .so files and path on your system and apply
-- Below config error you might get during any Cmake installation
-- cmake -DCURL_LIBRARY=/usr/lib64/libcurl.so -DCURL_INCLUDE_DIR=/usr/include/curl
-- cmake -DTIFF_LIBRARY=/usr/lib/libtiff.so -DTIFF_INCLUDE_DIR=/usr/include .

-- PROJ - Use latest Version/required
mkdir Proj
cd Proj
wget https://download.osgeo.org/proj/proj-9.5.1.tar.gz
tar -xvf proj-9.5.1.tar.gz
cd proj-9.5.1
mkdir build
cd build
cmake ..
cmake --build .
cmake --build . --target install
-- To check installed version
proj

-- Resolve issues on cmake during proj installation if you face
-- you might have installed below things already
-- I had issues. In my case, I followed below
cmake -DCMAKE_BUILD_TYPE=Release ..
cmake -DCURL_LIBRARY=/usr/lib64/libcurl.so -DCURL_INCLUDE_DIR=/usr/include/curl 
cmake -DTIFF_LIBRARY=/usr/lib/libtiff.so -DTIFF_INCLUDE_DIR=/usr/include .
cmake --build . && cmake --build . --target install

-- GDAL - Use latest Version/required (This may vary)
mkdir Gdal
cd Gdal
git clone https://github.com/OSGeo/gdal.git
cd gdal
mkdir build
cd build
cmake ..
make
sudo make install
-- To check installed version
gdalinfo --version

-- check below env variables, if not set, "source" it or it will affect the PostGIS
export GDAL_DATA="/usr/local/share/gdal"
export LD_LIBRARY_PATH=/usr/local/lib:/usr/local/lib64:$LD_LIBRARY_PATH

-- SFCGAL (Install if needed)
-- Note** Incase of SFCGAL support, it has to be installed
-- SFCGAL needs CGAL 
-- Install CGAL
mkdir cgal
cd cgal
wget https://github.com/CGAL/cgal/releases/download/v5.6/CGAL-5.6.tar.xz
tar -xf CGAL-5.6.tar.xz
cd CGAL-5.6/
mkdir build
cd build
cmake -DCMAKE_BUILD_TYPE=Release ..
make install
cd ../examples/Triangulation_2
cmake -DCGAL_DIR=$CMAKE_INSTALLED_PREFIX/lib/CGAL -DCMAKE_BUILD_TYPE=Release .
make (Just Build the Examples)
-- To check installed version
cat /usr/local/include/CGAL/version.h | grep CGAL_VERSION

-- Install SFCGAL
wget https://gitlab.com/SFCGAL/SFCGAL/-/archive/v2.0.0/SFCGAL-v2.0.0.tar.gz
mkdir Sfcgal
cd Sfcal/
cd SFCGAL-v2.0.0/
mkdir build
cd build
cmake -DCMAKE_BUILD_TYPE=Release ..
cmake --build .
cmake --build . --target install
-- To check installed version
sfcgal-config --version

-- PostGIS - Use latest Version/required
mkdir PostGIS
cd PostGIS
wget http://download.osgeo.org/postgis/source/postgis-3.5.2.tar.gz
tar zxvf postgis-3.5.2.tar.gz 
cd postgis-3.5.2
-- include sfcgal-config only if you have installed it
./configure --with-geosconfig=/usr/local/bin/geos-config --with-sfcgal=/usr/local/bin/sfcgal-config
make
sudo make install

--Create a temporary database to test

createdb -U postgres temp_postgis
psql -U postgres -d temp_postgis < /your/path/postgis.sql
psql -U postgres -d temp_postgis < /your/path/spatial_ref_sys.sql

-- Create the below Extensions
-- Enable PostGIS (includes raster)
CREATE EXTENSION postgis;

-- -------
-- WARNING
-- -------
-- dynamic_library_path is related to GEOS Installation
-- I made it since I had issue with GEOS Dependency
-- Related to LD_LIBRARY_PATH, if you face issues with reading (.so) files then change it
sudo vim /var/lib/pgsql/data/postgresql.conf

-- Uncomment the line
#dynamic_library_path = '$libdir'

-- Change like this
dynamic_library_path = '$libdir:/usr/local/lib64'

-- If you're seeing issue with creating extension still
-- Take backup of service file
cp /etc/systemd/system/multi-user.target.wants/postgresql.service /etc/systemd/system/multi-user.target.wants/postgresql.service.bak
-- Change below
Environment=PGDATA=/var/lib/pgsql/data
-- To read like this
Environment=PGDATA=/var/lib/pgsql/data LD_LIBRARY_PATH=/usr/local/lib:/usr/local/lib64:$LD_LIBRARY_PATH
systemctl daemon-reload
-- Restart the Postgres

-- Enable Topology
CREATE EXTENSION postgis_topology;

-- Enable Raster
CREATE EXTENSION postgis_raster;

-- Enable PostGIS Advanced 3D
-- and other geoprocessing algorithms
-- Note** - sfcgal not available with all distributions, create only if you have installed sfcal
CREATE EXTENSION postgis_sfcgal;

-- fuzzy matching needed for Tiger
CREATE EXTENSION fuzzystrmatch;

-- rule based standardizer
CREATE EXTENSION address_standardizer;

-- example rule data set
CREATE EXTENSION address_standardizer_data_us;

-- Enable US Tiger Geocoder
CREATE EXTENSION postgis_tiger_geocoder;

-- verify the installation
SELECT postgis_version();


Let's Test?
===========
-- create a sample table on temp_postgis
CREATE TABLE spatial_table (id SERIAL PRIMARY KEY, geom geometry(Point, 4326));

-- Insert a dummy record
INSERT INTO spatial_table (geom) VALUES (ST_SetSRID(ST_MakePoint(-73.9857, 40.7484), 4326));

-- Fetch the inserted, You must see the result
SELECT * FROM spatial_table WHERE ST_DWithin(geom, ST_MakePoint(-73.9857, 40.7484)::geography, 1000);

-- If you have done all the steps, crab a coffee and relax, Good Luck!


-- Okay, How to Import the Actudual Tiger Data and Test it? Follow below
=========================================================================

-- Update the Path as you want (Work Dir)
UPDATE tiger.loader_variables SET staging_fold = '/home/praveenkns/tiger/' WHERE staging_fold = '/gisdata/';

-- I am replicating the 'sh' to 'praveenkns' since I need some custom settings
INSERT INTO tiger.loader_platform (os, declare_sect, pgbin, wget, unzip_command, psql, path_sep, loader, environ_set_command, county_process_command)
SELECT 'praveenkns', declare_sect, pgbin, wget, unzip_command, psql, path_sep, loader, environ_set_command, county_process_command
FROM tiger.loader_platform
WHERE os = 'sh';

-- Update the Password on the replicated record, User etc with below query, for Ex
UPDATE tiger.loader_platform SET declare_sect = replace(declare_sect, 'export PGUSER=postgres', 'export PGUSER=praveenkns') WHERE os = 'praveenkns';

-- Replace the path details with below query, from where you want to update the data to DB
UPDATE tiger.loader_platform SET declare_sect = replace(declare_sect, '/gisdata/', '/home/praveenkns/tiger/') WHERE os = 'praveenkns';

-- Just like that, Update all the things

su user_name
cd /home/user_name

-- In my case praveenkns and I have created a database with the name geotiger
-- I have installed all the Extensions for geotiger
su praveenkns
cd /home/praveenkns
mkdir tiger
cd tiger
psql geotiger or psql -U postgres -d geotiger

-- run below query in the postgres

geotiger=# \copy (select loader_generate_script(ARRAY['AR'], 'praveenkns')) to '/home/praveenkns/tiger/state_ar.sh' with binary;

geotiger=# \copy (SELECT loader_generate_nation_script('praveenkns')) to '/home/praveenkns/tiger/nation_loader.sh' with binary;

-- The state code with ARRAY['AR'], change states based on the needes
-- For an ex, if you are importing Florida the ARRAY['FL'] and the script name will be state_fl.sh
-- Import one state by one state always, validate it, then move to next state.

-- You should be seeing the state_ar.sh under /home/praveenkns/tiger
vi state_ar.sh

-- Remove special characters from beginning and end of the Script
-- Quote the password, for example PASSWORD=ahgdfa -> PASSWORD='ahgdfa'
-- run the script with below, time taken to complete is based on the state size
sh state_ar.sh

-- Once the script ran with no errors, run the blow queries in psql which are used to create needed indexes
geotiger=# SELECT missing_indexes_generate_script();
geotiger=# SELECT install_missing_indexes();

-- Pick random lat, lon of village/city and test it out with below queries

-- Query1 : Reverse Geocoding.
-- I am using -93.456770 33.101497
SELECT pprint_addy(r.addy[1]) As st1,pprint_addy(r.addy[2]) As st2,pprint_addy(r.addy[3]) As st3,array_to_string(r.street, ',') As cross_streets FROM reverse_geocode(ST_GeomFromText('POINT(-71.42228383385718 41.82108765408063)',4269),true) As r;

-- Query2 : Geocoding.
-- I am using 541 CEDARBROOK RD (KIDS ON RIGHT & LEFT),JONESVILLE,NC,28642
SELECT g.rating, ST_X(g.geomout) As lon, ST_Y(g.geomout) As lat, (addy).address As stno, (addy).streetname As street, (addy).streettypeabbrev As styp, (addy).location As city, (addy).stateabbrev As st, (addy).zip FROM geocode('817 Gardenia St,Lake Placid,FL,33862') As g;

-- Query3 : Geocode intersections between two streets.
-- I am using Street 1, Street 2, State, City
SELECT g.rating,ST_X(g.geomout) As lon,ST_Y(g.geomout) As lat,(addy).address As stno,(addy).streetname As street,(addy).streettypeabbrev As styp,(addy).location As city,(addy).stateabbrev As st,(addy).zip,pprint_addy(addy), st_astext(geomout),rating  FROM geocode_intersection('E Spring St','Robinson Ave', 'AR', 'Taylor') AS g;

-- Once the validation is completed delete the folders from /home/praveenkns apart from the script file

Fault Tolerance:
----------------
-- If you face issue with importing data and you want to revert back, follow below, 'fl' is a state code

SELECT table_name FROM information_schema.tables WHERE table_schema = 'tiger_data' AND table_name LIKE 'fl%';

-- Delete all the tables related to the state which you wanted to revert (It deletes including indexes as well)
DROP TABLE IF EXISTS tiger_data.fl_addr,tiger_data.fl_cousub,tiger_data.fl_edges,tiger_data.fl_faces,tiger_data.fl_featnames,tiger_data.fl_place,tiger_data.fl_tabblock20,tiger_data.fl_tract,tiger_data.fl_zip_lookup_base,tiger_data.fl_zip_state,tiger_data.fl_zip_state_loc;

-- Upgrading? (As of my concern):
-- ------------------------------
-- Since all the things are installed from source and all are dependent to each other, there are high chances for misbehavior
-- if you upgrade, it may lead into duplicate versions for the most installed
-- It is better to do the installation from Scratch with the instructions given

-- Updating the data? (As of my concern):
-----------------------------------------
-- I find no way to update, as the tiger data relies on the PostGIS version, The PostGIS is what decides which year of data need to be imported.
-- Try with your own risk

select * from tiger.loader_variables;

-- You might notice the year and cencus repo link, update with the year you need, create the script file and import
-- Success? Great! Mostly it will fail with column and values mismatch (Fail = New Server Setup), TC!
